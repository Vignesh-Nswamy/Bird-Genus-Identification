{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wLrirP19DAu2"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os\n",
    "import librosa\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e2YlnNF_rjA_"
   },
   "outputs": [],
   "source": [
    "train_set = numpy.load('train_data.npz')\n",
    "x_train = train_set['arr_0']\n",
    "y_train = train_set['arr_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ZWd4c-TeXge"
   },
   "outputs": [],
   "source": [
    "test_set = numpy.load('test_data.npz')\n",
    "x_test = test_set['arr_0']\n",
    "y_test = test_set['arr_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6fk8mnWdDi5N"
   },
   "outputs": [],
   "source": [
    "def init_parallel_crnn(input_shape):  \n",
    "  n_classes = 141\n",
    "  conv_kernel_size = (3, 1)\n",
    "  lstm_hidden_units = 64\n",
    "  # Input layer\n",
    "  input_layer = tf.keras.layers.Input(input_shape, name='input')\n",
    "  # Convolutional branch\n",
    "  # convolution 1\n",
    "  conv_1 = tf.keras.layers.Conv2D(16, conv_kernel_size, activation='relu')(input_layer)\n",
    "  max_pool_1 = tf.keras.layers.MaxPooling2D(2, 2)(conv_1)\n",
    "  # convolution 2\n",
    "  conv_2 = tf.keras.layers.Conv2D(32, conv_kernel_size, activation='relu')(max_pool_1)\n",
    "  max_pool_2 = tf.keras.layers.MaxPooling2D(2,2)(conv_2)\n",
    "  # dropout_1 = tf.keras.layers.Dropout(0.5)(max_pool_2)\n",
    "  # convolution 3\n",
    "  conv_3 = tf.keras.layers.Conv2D(64, conv_kernel_size, activation='relu')(max_pool_2)\n",
    "  max_pool_3 = tf.keras.layers.MaxPooling2D(2,2)(conv_3)\n",
    "  # convolution 4\n",
    "  conv_4 = tf.keras.layers.Conv2D(64, conv_kernel_size, activation='relu')(max_pool_3)\n",
    "  max_pool_4 = tf.keras.layers.MaxPooling2D(4,4)(conv_4)\n",
    "  # dropout_2 = tf.keras.layers.Dropout(0.5)(max_pool_4)\n",
    "  conv_5 = tf.keras.layers.Conv2D(64, conv_kernel_size, activation='relu')(max_pool_4)\n",
    "  max_pool_5 = tf.keras.layers.MaxPooling2D((4, 4))(conv_5)\n",
    "  # Flatten\n",
    "  flatten_1 = tf.keras.layers.Flatten()(max_pool_5)\n",
    "  # Recurrent branch\n",
    "  max_pool_lstm = tf.keras.layers.MaxPooling2D(2, 2)(input_layer)\n",
    "  squeeze_lambda = tf.keras.layers.Lambda(lambda x: tf.keras.backend.squeeze(x, axis= -1))(max_pool_lstm)\n",
    "  lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_hidden_units))(squeeze_lambda)\n",
    "  # Concatenate convolutional and recurrent branches\n",
    "  combine_cnn_rnn = tf.keras.layers.concatenate([flatten_1, lstm], axis=-1, name ='combine')\n",
    "  # dropout_3 = tf.keras.layers.Dropout(0.5)(combine_cnn_rnn)\n",
    "  output_layer = tf.keras.layers.Dense(n_classes, activation='softmax')(combine_cnn_rnn)\n",
    "  model = tf.keras.models.Model(input_layer, output_layer)\n",
    "  \n",
    "  print(model.summary())\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qQoGsw1QUv5P"
   },
   "outputs": [],
   "source": [
    "def init_crnn(input_shape):  \n",
    "  n_classes = 141\n",
    "  n_hidden = 200\n",
    "  conv_kernel_size = (3, 1)\n",
    "  lstm_hidden_units = 96\n",
    "  num_conv_layers = 6\n",
    "  layers = []\n",
    "  layers.append(tf.keras.layers.Input(input_shape, name='input'))\n",
    "  for i in range(num_conv_layers):\n",
    "    layers.append(tf.keras.layers.Conv1D(filters=56, kernel_size=5, kernel_regularizer=tf.keras.regularizers.l2(0.001), name='conv_'+str(i)))\n",
    "    layers.append(tf.keras.layers.BatchNormalization(momentum=0.9, name='bNorm_'+str(i)))\n",
    "    layers.append(tf.keras.layers.Activation('relu', name='act_'+str(i)))\n",
    "    layers.append(tf.keras.layers.MaxPooling1D(2, name='max_pool_'+str(i)))\n",
    "  layers.append(tf.keras.layers.LSTM(lstm_hidden_units, return_sequences=False))\n",
    "  layers.append(tf.keras.layers.Dropout(0.2, name='dropout_1'))\n",
    "  layers.append(tf.keras.layers.Dense(n_classes*4, activation='relu', name='dense_1'))\n",
    "  layers.append(tf.keras.layers.Dropout(0.3, name='dropout_2'))\n",
    "  layers.append(tf.keras.layers.Dense(n_classes*2, activation='relu', name='dense_2'))\n",
    "  layers.append(tf.keras.layers.Dropout(0.3, name='dropout_3'))\n",
    "  layers.append(tf.keras.layers.Dense(n_classes, activation='softmax', name='dense_3'))\n",
    "  model = tf.keras.models.Sequential(layers)\n",
    "  print(model.summary())\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BXuJRiJoZT4r"
   },
   "outputs": [],
   "source": [
    "def init_simple_rnn(input_shape):  \n",
    "  n_classes = 141\n",
    "  n_hidden = 200\n",
    "  model = tf.keras.models.Sequential([tf.keras.layers.LSTM(256, input_shape=input_shape, return_sequences=False),\n",
    "                                     tf.keras.layers.Dropout(0.2),\n",
    "                                     tf.keras.layers.Dense(n_hidden, kernel_regularizer=tf.keras.regularizers.l2(0.001), activation='relu'),\n",
    "                                     tf.keras.layers.Dropout(0.2),\n",
    "                                     tf.keras.layers.Dense(n_classes, activation='softmax')])  \n",
    "  \n",
    "  print(model.summary())\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ox7go3F_dcSb"
   },
   "outputs": [],
   "source": [
    "reducelr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_acc',\n",
    "                                                         factor=0.2,\n",
    "                                                         patience=5,\n",
    "                                                         min_delta=0.01,verbose=1)\n",
    "\n",
    "callbacks_list = [reducelr_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UHM1iik1k5Z-"
   },
   "outputs": [],
   "source": [
    "def build_crnn(x_train, y_train, x_test, y_test, callbacks):\n",
    "  n_features = x_train.shape[2]\n",
    "  n_time_frames = x_train.shape[1]\n",
    "  opt = tf.keras.optimizers.RMSprop(lr=0.0005)  # Optimizer\n",
    "  model = init_crnn((n_time_frames, n_features))\n",
    "  model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=opt,\n",
    "                metrics=['accuracy'])\n",
    "  history = model.fit(x_train, y_train, epochs=50, batch_size=64, verbose=2, validation_split=0.2, callbacks=callbacks)\n",
    "  results = model.evaluate(x_test, y_test, batch_size=128)\n",
    "  print('test loss, test acc:', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "vhfOF7NqoGHx",
    "outputId": "f3aba295-9734-4b28-b5ab-c9e2e8f74bb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_0 (Conv1D)              (None, 858, 56)           35896     \n",
      "_________________________________________________________________\n",
      "bNorm_0 (BatchNormalization) (None, 858, 56)           224       \n",
      "_________________________________________________________________\n",
      "act_0 (Activation)           (None, 858, 56)           0         \n",
      "_________________________________________________________________\n",
      "max_pool_0 (MaxPooling1D)    (None, 429, 56)           0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv1D)              (None, 425, 56)           15736     \n",
      "_________________________________________________________________\n",
      "bNorm_1 (BatchNormalization) (None, 425, 56)           224       \n",
      "_________________________________________________________________\n",
      "act_1 (Activation)           (None, 425, 56)           0         \n",
      "_________________________________________________________________\n",
      "max_pool_1 (MaxPooling1D)    (None, 212, 56)           0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv1D)              (None, 208, 56)           15736     \n",
      "_________________________________________________________________\n",
      "bNorm_2 (BatchNormalization) (None, 208, 56)           224       \n",
      "_________________________________________________________________\n",
      "act_2 (Activation)           (None, 208, 56)           0         \n",
      "_________________________________________________________________\n",
      "max_pool_2 (MaxPooling1D)    (None, 104, 56)           0         \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv1D)              (None, 100, 56)           15736     \n",
      "_________________________________________________________________\n",
      "bNorm_3 (BatchNormalization) (None, 100, 56)           224       \n",
      "_________________________________________________________________\n",
      "act_3 (Activation)           (None, 100, 56)           0         \n",
      "_________________________________________________________________\n",
      "max_pool_3 (MaxPooling1D)    (None, 50, 56)            0         \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv1D)              (None, 46, 56)            15736     \n",
      "_________________________________________________________________\n",
      "bNorm_4 (BatchNormalization) (None, 46, 56)            224       \n",
      "_________________________________________________________________\n",
      "act_4 (Activation)           (None, 46, 56)            0         \n",
      "_________________________________________________________________\n",
      "max_pool_4 (MaxPooling1D)    (None, 23, 56)            0         \n",
      "_________________________________________________________________\n",
      "conv_5 (Conv1D)              (None, 19, 56)            15736     \n",
      "_________________________________________________________________\n",
      "bNorm_5 (BatchNormalization) (None, 19, 56)            224       \n",
      "_________________________________________________________________\n",
      "act_5 (Activation)           (None, 19, 56)            0         \n",
      "_________________________________________________________________\n",
      "max_pool_5 (MaxPooling1D)    (None, 9, 56)             0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 96)                58752     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 564)               54708     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 564)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 282)               159330    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 282)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 141)               39903     \n",
      "=================================================================\n",
      "Total params: 428,613\n",
      "Trainable params: 427,941\n",
      "Non-trainable params: 672\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 3972 samples, validate on 993 samples\n",
      "Epoch 1/50\n",
      "3972/3972 - 13s - loss: 5.0886 - acc: 0.0428 - val_loss: 5.1442 - val_acc: 0.0423\n",
      "Epoch 2/50\n",
      "3972/3972 - 11s - loss: 4.7966 - acc: 0.0831 - val_loss: 4.9694 - val_acc: 0.0554\n",
      "Epoch 3/50\n",
      "3972/3972 - 11s - loss: 4.5266 - acc: 0.1148 - val_loss: 4.9145 - val_acc: 0.0604\n",
      "Epoch 4/50\n",
      "3972/3972 - 11s - loss: 4.2781 - acc: 0.1354 - val_loss: 4.3966 - val_acc: 0.1078\n",
      "Epoch 5/50\n",
      "3972/3972 - 11s - loss: 4.0296 - acc: 0.1682 - val_loss: 4.9850 - val_acc: 0.0463\n",
      "Epoch 6/50\n",
      "3972/3972 - 11s - loss: 3.8556 - acc: 0.1871 - val_loss: 5.1705 - val_acc: 0.0463\n",
      "Epoch 7/50\n",
      "3972/3972 - 11s - loss: 3.6726 - acc: 0.2052 - val_loss: 4.3142 - val_acc: 0.1420\n",
      "Epoch 8/50\n",
      "3972/3972 - 11s - loss: 3.5613 - acc: 0.2208 - val_loss: 6.2068 - val_acc: 0.0463\n",
      "Epoch 9/50\n",
      "3972/3972 - 11s - loss: 3.3694 - acc: 0.2475 - val_loss: 4.1667 - val_acc: 0.1390\n",
      "Epoch 10/50\n",
      "3972/3972 - 11s - loss: 3.3001 - acc: 0.2626 - val_loss: 5.6359 - val_acc: 0.0604\n",
      "Epoch 11/50\n",
      "3972/3972 - 11s - loss: 3.1894 - acc: 0.2772 - val_loss: 4.8234 - val_acc: 0.0685\n",
      "Epoch 12/50\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "3972/3972 - 11s - loss: 3.0671 - acc: 0.2998 - val_loss: 5.4245 - val_acc: 0.1138\n",
      "Epoch 13/50\n",
      "3972/3972 - 11s - loss: 2.8858 - acc: 0.3301 - val_loss: 3.2793 - val_acc: 0.2880\n",
      "Epoch 14/50\n",
      "3972/3972 - 11s - loss: 2.7387 - acc: 0.3625 - val_loss: 3.2148 - val_acc: 0.2920\n",
      "Epoch 15/50\n",
      "3972/3972 - 11s - loss: 2.6848 - acc: 0.3666 - val_loss: 3.1963 - val_acc: 0.3021\n",
      "Epoch 16/50\n",
      "3972/3972 - 11s - loss: 2.6577 - acc: 0.3671 - val_loss: 3.4929 - val_acc: 0.2679\n",
      "Epoch 17/50\n",
      "3972/3972 - 11s - loss: 2.6257 - acc: 0.3781 - val_loss: 3.2666 - val_acc: 0.3021\n",
      "Epoch 18/50\n",
      "3972/3972 - 11s - loss: 2.5589 - acc: 0.4018 - val_loss: 3.4265 - val_acc: 0.2961\n",
      "Epoch 19/50\n",
      "3972/3972 - 11s - loss: 2.5313 - acc: 0.3975 - val_loss: 3.2982 - val_acc: 0.3021\n",
      "Epoch 20/50\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "3972/3972 - 11s - loss: 2.4678 - acc: 0.4086 - val_loss: 3.1724 - val_acc: 0.3092\n",
      "Epoch 21/50\n",
      "3972/3972 - 11s - loss: 2.4028 - acc: 0.4323 - val_loss: 3.1291 - val_acc: 0.3293\n",
      "Epoch 22/50\n",
      "3972/3972 - 11s - loss: 2.3742 - acc: 0.4338 - val_loss: 3.1316 - val_acc: 0.3233\n",
      "Epoch 23/50\n",
      "3972/3972 - 11s - loss: 2.3749 - acc: 0.4361 - val_loss: 3.1177 - val_acc: 0.3384\n",
      "Epoch 24/50\n",
      "3972/3972 - 11s - loss: 2.3918 - acc: 0.4293 - val_loss: 3.1052 - val_acc: 0.3313\n",
      "Epoch 25/50\n",
      "3972/3972 - 11s - loss: 2.3394 - acc: 0.4464 - val_loss: 3.1288 - val_acc: 0.3404\n",
      "Epoch 26/50\n",
      "3972/3972 - 11s - loss: 2.3521 - acc: 0.4416 - val_loss: 3.1288 - val_acc: 0.3263\n",
      "Epoch 27/50\n",
      "3972/3972 - 11s - loss: 2.3263 - acc: 0.4428 - val_loss: 3.1294 - val_acc: 0.3333\n",
      "Epoch 28/50\n",
      "3972/3972 - 11s - loss: 2.3402 - acc: 0.4366 - val_loss: 3.1302 - val_acc: 0.3343\n",
      "Epoch 29/50\n",
      "3972/3972 - 12s - loss: 2.3213 - acc: 0.4436 - val_loss: 3.1678 - val_acc: 0.3283\n",
      "Epoch 30/50\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "3972/3972 - 11s - loss: 2.3306 - acc: 0.4413 - val_loss: 3.1306 - val_acc: 0.3394\n",
      "Epoch 31/50\n",
      "3972/3972 - 11s - loss: 2.3062 - acc: 0.4439 - val_loss: 3.1376 - val_acc: 0.3353\n",
      "Epoch 32/50\n",
      "3972/3972 - 11s - loss: 2.2845 - acc: 0.4411 - val_loss: 3.1423 - val_acc: 0.3343\n",
      "Epoch 33/50\n",
      "3972/3972 - 11s - loss: 2.2867 - acc: 0.4567 - val_loss: 3.1258 - val_acc: 0.3273\n",
      "Epoch 34/50\n",
      "3972/3972 - 11s - loss: 2.2837 - acc: 0.4509 - val_loss: 3.1299 - val_acc: 0.3394\n",
      "Epoch 35/50\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 8.000000889296644e-07.\n",
      "3972/3972 - 11s - loss: 2.3037 - acc: 0.4451 - val_loss: 3.1448 - val_acc: 0.3323\n",
      "Epoch 36/50\n",
      "3972/3972 - 11s - loss: 2.2620 - acc: 0.4602 - val_loss: 3.1426 - val_acc: 0.3283\n",
      "Epoch 37/50\n",
      "3972/3972 - 11s - loss: 2.3005 - acc: 0.4476 - val_loss: 3.1331 - val_acc: 0.3313\n",
      "Epoch 38/50\n",
      "3972/3972 - 11s - loss: 2.2758 - acc: 0.4537 - val_loss: 3.1434 - val_acc: 0.3273\n",
      "Epoch 39/50\n",
      "3972/3972 - 11s - loss: 2.2981 - acc: 0.4439 - val_loss: 3.1266 - val_acc: 0.3414\n",
      "Epoch 40/50\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.6000001323845936e-07.\n",
      "3972/3972 - 11s - loss: 2.2685 - acc: 0.4595 - val_loss: 3.1327 - val_acc: 0.3323\n",
      "Epoch 41/50\n",
      "3972/3972 - 11s - loss: 2.2990 - acc: 0.4413 - val_loss: 3.1411 - val_acc: 0.3223\n",
      "Epoch 42/50\n",
      "3972/3972 - 11s - loss: 2.2898 - acc: 0.4544 - val_loss: 3.1526 - val_acc: 0.3283\n",
      "Epoch 43/50\n",
      "3972/3972 - 11s - loss: 2.2838 - acc: 0.4582 - val_loss: 3.1391 - val_acc: 0.3444\n",
      "Epoch 44/50\n",
      "3972/3972 - 11s - loss: 2.2893 - acc: 0.4426 - val_loss: 3.1429 - val_acc: 0.3303\n",
      "Epoch 45/50\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-08.\n",
      "3972/3972 - 11s - loss: 2.2790 - acc: 0.4534 - val_loss: 3.1265 - val_acc: 0.3384\n",
      "Epoch 46/50\n",
      "3972/3972 - 11s - loss: 2.2902 - acc: 0.4519 - val_loss: 3.1334 - val_acc: 0.3364\n",
      "Epoch 47/50\n",
      "3972/3972 - 11s - loss: 2.2705 - acc: 0.4632 - val_loss: 3.1332 - val_acc: 0.3353\n",
      "Epoch 48/50\n",
      "3972/3972 - 11s - loss: 2.2901 - acc: 0.4514 - val_loss: 3.1378 - val_acc: 0.3414\n",
      "Epoch 49/50\n",
      "3972/3972 - 11s - loss: 2.2915 - acc: 0.4517 - val_loss: 3.1607 - val_acc: 0.3313\n",
      "Epoch 50/50\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-09.\n",
      "3972/3972 - 11s - loss: 2.2884 - acc: 0.4559 - val_loss: 3.1229 - val_acc: 0.3404\n",
      "1242/1242 [==============================] - 1s 906us/sample - loss: 3.0856 - acc: 0.3333\n",
      "test loss, test acc: [3.0855814780973967, 0.33333334]\n"
     ]
    }
   ],
   "source": [
    "build_crnn(x_train_set, y_train_set, x_test, y_test, callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ok8azRlUfyyR"
   },
   "outputs": [],
   "source": [
    "def build_rnn(x_train, y_train, x_test, y_test, callbacks):\n",
    "  n_features = x_train.shape[2]\n",
    "  n_time_frames = x_train.shape[1]\n",
    "  opt = tf.keras.optimizers.RMSprop(lr=0.0005)  # Optimizer\n",
    "  model = init_simple_rnn((n_time_frames, n_features))\n",
    "  model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=opt,\n",
    "                metrics=['accuracy'])\n",
    "  history = model.fit(x_train, y_train, epochs=50, batch_size=64, verbose=2, validation_split=0.2, callbacks=callbacks)\n",
    "  results = model.evaluate(x_test, y_test, batch_size=128)\n",
    "  print('test loss, test acc:', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lVzkLl4chAbw"
   },
   "outputs": [],
   "source": [
    "build_rnn(x_train, y_train, x_test, y_test, callbacks_list)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "model_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
